# Automated llms.txt Generator

## Objective
Develop a tool that automatically generates an llms.txt file for a given website by analyzing its structure and content.

## Background
The llms.txt file is a proposed standard designed to help Large Language Models (LLMs) better understand and interact with website content. Similar to robots.txt, which guides search engine crawlers, llms.txt provides structured information tailored for AI systems, enhancing their ability to process and utilize web data effectively.

## Assignment Tasks

Build a web application that allows a user to input a website URL and receive a generated llms.txt file. The design and user experience of this tool is up to you.

**Website Analysis and Content Extraction:**
Develop a crawler that traverses the website to identify key pages and extract relevant metadata, such as titles, descriptions, and URLs.

**llms.txt File Generation:**
Structure the extracted data into the llms.txt format. Your implementation should conform to the spec at llmstxt.org.

**Documentation:**
Provide clear instructions on how to set up, configure, and use the tool.

It is up to you to design how the user interacts with this tool. Build a web application the user directly visits to create the llms.txt.

## Evaluation Criteria
- **Functionality:** The tool should accurately generate an llms.txt file that reflects the website's structure and content.
- **Code Quality:** The code should be well-structured, readable, and maintainable.
- **Documentation:** Clear and comprehensive documentation should accompany the tool, facilitating easy setup and usage.

## Additional Resources
- **llms.txt Specification:**
  https://llmstxt.org/
- **Examples:**
  https://llmstxt.site/
  This is a public directory. The llms.txt file may not meet the specifications. It is for reference only.
- **Getting Started with llms.txt:**
  https://llmstxthub.com/guides/getting-started-llms-txt

## Deliverables
- A live, deployed version of the application. Deploy to a hosting platform of your choice.
- Source code in a GitHub repo.
- A README.md with setup and deployment instructions.
- Screenshots of the project, or alternatively a short demo video.

## Submission
Create a GitHub repo and add the following collaborators (members of our technical staff):
- chazzhou
- allapk19
- sherman-grewal
- joshuaprunty
- nuarmstrong
- rahibk
- joeydotdev
- kirk-xuhj
- bgaleotti
- fedeya

## Notes
**On using AI:** AI tools are fair game, but own your code. During your presentation, we'll ask you to explain your architecture, trade-offs, and implementation details. If AI wrote it, you should understand it well enough to have written it yourself.

**On time:** There is no strict time limit. We recognize candidates have varying availability, and the depth and polish of your submission is itself a signal. That said, we'd rather see a well-understood, well-crafted solution than a sprawling one you can't explain.

Your work is yours to keep and you are free to show it off as a portfolio project, but please do not disclose this document publicly.

By submitting your repository, you grant us permission to fork it for the sole purpose of internal documentation and evaluation. This includes the use of automated tools (such as AI-based scanners) to help assess code quality. Your work will remain private and will only be used as part of our evaluation process.

## About Profound and Engineering Culture
Profound is building the infrastructure layer for marketing in the generative internet. We're a data, search, and applied AI company at our core. Today, that means helping brands understand where and how they appear across AI interfaces like ChatGPT and Perplexity. Tomorrow, it means being the infrastructure companies rely on as AI agents, generative ads, and new discovery surfaces reshape how consumers find information.

In engineering, we value speed, craftsmanship, and clear communication. As Linus Torvalds said, "Talk is cheap; show me the code." This project is your chance to show us how you think, build, and ship.
